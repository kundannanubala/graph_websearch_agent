from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage
from agents.agents import (
    AnalysisNode2Agent,
    FeedbackGenerationAgent,
    ScoringAgent,
    ParaphrasingAgent,
)
from tools.preprocessing_tool import preprocessing_tool
from tools.analysis_node1_tool import analysis_node1_tool
from tools.knowledge_base_loader import knowledge_base_loader
from tools.format_report import format_report
from states.state import AgentGraphState

def create_graph(server=None, model=None, stop=None, model_endpoint=None, temperature=0):
    graph = StateGraph(AgentGraphState)

    # KnowledgeBaseLoading Node
    graph.add_node(
        "knowledgeBase",
        lambda state: knowledge_base_loader(state)
    )

    # Preprocessing Node
    graph.add_node(
        "preprocessing",
        lambda state: preprocessing_tool(state)
    )

    # Analysis Node 1
    graph.add_node(
        "analysis_node1",
        lambda state: analysis_node1_tool(state)
    )

    # Analysis Node 2
    graph.add_node(
        "analysis_node2",
        lambda state: AnalysisNode2Agent(
            state=state,
            model=model,
            server=server,
            stop=stop,
            model_endpoint=model_endpoint,
            temperature=temperature
        ).invoke(state)
    )

    # Feedback Generation Node
    graph.add_node(
        "feedback_generation",
        lambda state: FeedbackGenerationAgent(
            state=state,
            model=model,
            server=server,
            stop=stop,
            model_endpoint=model_endpoint,
            temperature=temperature
        ).invoke(state)
    )

    # Scoring Node
    graph.add_node(
        "scoring",
        lambda state: ScoringAgent(
            state=state,
            model=model,
            server=server,
            stop=stop,
            model_endpoint=model_endpoint,
            temperature=temperature
        ).invoke(state)
    )

    # Paraphrasing Node
    graph.add_node(
        "paraphrasing",
        lambda state: ParaphrasingAgent(
            state=state,
            model=model,
            server=server,
            stop=stop,
            model_endpoint=model_endpoint,
            temperature=temperature
        ).invoke(state)
    )

    graph.add_node(
        "report_generation",
        lambda state: format_report(state)
    )

    # Set the entry point
    graph.set_entry_point("knowledgeBase")

    # Set the finish point
    graph.set_finish_point("report_generation")

    # Add edges to connect the nodes
    graph.add_edge("knowledgeBase", "preprocessing")
    graph.add_edge("preprocessing", "analysis_node1")
    graph.add_edge("analysis_node1", "analysis_node2")
    graph.add_edge("analysis_node2", "feedback_generation")
    graph.add_edge("feedback_generation", "scoring")
    graph.add_edge("scoring", "paraphrasing")
    graph.add_edge("paraphrasing", "report_generation")

    return graph

def compile_workflow(graph):
    workflow = graph.compile()
    return workflow
# import json
# import yaml
# import os
from termcolor import colored
from models.openai_models import get_open_ai, get_open_ai_json
from models.ollama_models import OllamaModel, OllamaJSONModel
from models.vllm_models import VllmJSONModel, VllmModel
from models.groq_models import GroqModel, GroqJSONModel
from models.claude_models import ClaudVertexModel, ClaudVertexJSONModel
from models.gemini_models import GeminiModel, GeminiJSONModel
from langchain_core.messages import HumanMessage
import json
from datetime import datetime
from prompts.prompts import (
    analysis_node2_prompt,
    feedback_generation_prompt,
    scoring_prompt,
    paraphrasing_prompt
)
from utils.helper_functions import get_current_utc_datetime, check_for_content
from states.state import AgentGraphState
from pymongo import MongoClient

# # MongoDB connection setup
# client = MongoClient('mongodb://localhost:27017/')
# db = client['FeedParser']  # This is your database name

class Agent:
    def __init__(self, state: AgentGraphState, model=None, server=None, temperature=0, model_endpoint=None, stop=None, guided_json=None):
        self.state = state
        self.model = model
        self.server = server
        self.temperature = temperature
        self.model_endpoint = model_endpoint
        self.stop = stop
        self.guided_json = guided_json

    def get_llm(self, json_model=True):
        if self.server == 'openai':
            return get_open_ai_json(model=self.model, temperature=self.temperature) if json_model else get_open_ai(model=self.model, temperature=self.temperature)
        if self.server == 'ollama':
            return OllamaJSONModel(model=self.model, temperature=self.temperature) if json_model else OllamaModel(model=self.model, temperature=self.temperature)
        if self.server == 'vllm':
            return VllmJSONModel(
                model=self.model, 
                guided_json=self.guided_json,
                stop=self.stop,
                model_endpoint=self.model_endpoint,
                temperature=self.temperature
            ) if json_model else VllmModel(
                model=self.model,
                model_endpoint=self.model_endpoint,
                stop=self.stop,
                temperature=self.temperature
            )
        if self.server == 'groq':
            return GroqJSONModel(
                model=self.model,
                temperature=self.temperature
            ) if json_model else GroqModel(
                model=self.model,
                temperature=self.temperature
            )
        if self.server == 'claude':
            return ClaudVertexJSONModel(
                model=self.model,
                temperature=self.temperature
            ) if json_model else ClaudVertexModel(
                model=self.model,
                temperature=self.temperature
            )
        if self.server == 'gemini':
            return GeminiJSONModel(
                model=self.model,
                temperature=self.temperature
            ) if json_model else GeminiModel(
                model=self.model,
                temperature=self.temperature
            )      

    def update_state(self, key, value):
        self.state = {**self.state, key: value}


class AnalysisNode2Agent(Agent):
    def invoke(self, state):
        preprocessed_data = next((msg.content for msg in state["messages"] if msg.role == "preprocessing"), None)
        analysis_node1_results = next((msg.content for msg in state["messages"] if msg.role == "analysis_node1"), None)
        knowledge_base = next((msg.content for msg in state["messages"] if msg.role == "knowledgeBase"), None)

        if not all([preprocessed_data, analysis_node1_results, knowledge_base]):
            raise ValueError("Missing required data in state")

        preprocessed_data = json.loads(preprocessed_data)
        analysis_node1_results = json.loads(analysis_node1_results)
        knowledge_base = json.loads(knowledge_base)

        messages = [
            {"role": "system", "content": analysis_node2_prompt.format(
                text=preprocessed_data['text'],
                analysis_results=json.dumps(analysis_node1_results, indent=2),
                knowledge_base=json.dumps(knowledge_base, indent=2)
            )},
            {"role": "user", "content": "Please provide your analysis."}
        ]

        llm = self.get_llm()
        ai_msg = llm.invoke(messages)

        state["messages"].append(
            HumanMessage(role="analysis_node2", content=ai_msg.content)
        )
        response=ai_msg.content
        with open("D:/VentureInternship/AI Agent/ProjectK/response.txt",'a') as file:
            file.write(f'\nAnalysis Node 2 response:{response}\n')

        return {"messages": state["messages"]}

class FeedbackGenerationAgent(Agent):
    def invoke(self, state):
        preprocessed_data = next((msg.content for msg in state["messages"] if msg.role == "preprocessing"), None)
        analysis_node1_results = next((msg.content for msg in state["messages"] if msg.role == "analysis_node1"), None)
        analysis_node2_results = next((msg.content for msg in state["messages"] if msg.role == "analysis_node2"), None)
        knowledge_base = next((msg.content for msg in state["messages"] if msg.role == "knowledgeBase"), None)

        if not all([preprocessed_data, analysis_node1_results, analysis_node2_results, knowledge_base]):
            raise ValueError("Missing required data in state")

        preprocessed_data = json.loads(preprocessed_data)
        analysis_node1_results = json.loads(analysis_node1_results)
        analysis_node2_results = json.loads(analysis_node2_results)
        knowledge_base = json.loads(knowledge_base)

        messages = [
            {"role": "system", "content": feedback_generation_prompt.format(
                text=preprocessed_data['text'],
                analysis_results=json.dumps({**analysis_node1_results, **analysis_node2_results}, indent=2),
                knowledge_base=json.dumps(knowledge_base, indent=2)
            )},
            {"role": "user", "content": "Please provide your detailed feedback."}
        ]

        llm = self.get_llm()
        ai_msg = llm.invoke(messages)
        response=ai_msg.content
        with open("D:/VentureInternship/AI Agent/ProjectK/response.txt",'a') as file:
            file.write(f'\Feedback Node response:{response}\n')        

        state["messages"].append(
            HumanMessage(role="feedback_generation", content=ai_msg.content)
        )

        return {"messages": state["messages"]}

class ScoringAgent(Agent):
    def invoke(self, state):
        analysis_node1_results = next((msg.content for msg in state["messages"] if msg.role == "analysis_node1"), None)
        analysis_node2_results = next((msg.content for msg in state["messages"] if msg.role == "analysis_node2"), None)
        knowledge_base = next((msg.content for msg in state["messages"] if msg.role == "knowledgeBase"), None)

        if not all([analysis_node1_results, analysis_node2_results, knowledge_base]):
            raise ValueError("Missing required data in state")

        analysis_node1_results = json.loads(analysis_node1_results)
        analysis_node2_results = json.loads(analysis_node2_results)
        knowledge_base = json.loads(knowledge_base)

        messages = [
            {"role": "system", "content": scoring_prompt.format(
                analysis_results=json.dumps({**analysis_node1_results, **analysis_node2_results}, indent=2),
                knowledge_base=json.dumps(knowledge_base, indent=2)
            )},
            {"role": "user", "content": "Please provide the IELTS writing score breakdown."}
        ]

        llm = self.get_llm()
        ai_msg = llm.invoke(messages)
        response=ai_msg.content
        with open("D:/VentureInternship/AI Agent/ProjectK/response.txt",'a') as file:
            file.write(f'\Scoring Node response:{response}\n')        

        state["messages"].append(
            HumanMessage(role="scoring", content=ai_msg.content)
        )

        return {"messages": state["messages"]}

class ParaphrasingAgent(Agent):
    def invoke(self, state):
        preprocessed_data = next((msg.content for msg in state["messages"] if msg.role == "preprocessing"), None)
        scoring_results = next((msg.content for msg in state["messages"] if msg.role == "scoring"), None)
        knowledge_base = next((msg.content for msg in state["messages"] if msg.role == "knowledgeBase"), None)

        if not all([preprocessed_data, scoring_results, knowledge_base]):
            raise ValueError("Missing required data in state")

        preprocessed_data = json.loads(preprocessed_data)
        scoring_results = json.loads(scoring_results)
        knowledge_base = json.loads(knowledge_base)

        messages = [
            {"role": "system", "content": paraphrasing_prompt.format(
                text=preprocessed_data['text'],
                scores=json.dumps(scoring_results, indent=2),
                knowledge_base=json.dumps(knowledge_base, indent=2)
            )},
            {"role": "user", "content": "Please provide the improved, Band 8 level paraphrased version."}
        ]

        llm = self.get_llm()
        ai_msg = llm.invoke(messages)

        try:
            response_content = json.loads(ai_msg.content)
        except json.JSONDecodeError:
            response_content = {"raw_text": ai_msg.content}
        response=ai_msg.content
        with open("D:/VentureInternship/AI Agent/ProjectK/response.txt",'a') as file:
            file.write(f'\Paraphrasing Node response:{response}\n')            

        state["messages"].append(
            HumanMessage(role="paraphrasing", content=json.dumps(response_content))
        )

        return {"messages": state["messages"]}
import tkinter as tk
from tkinter import simpledialog, messagebox
from agent_graph.graph import create_graph, compile_workflow

# Server and model configuration
server = 'claude'
model = "claude-3-5-sonnet@20240620"
model_endpoint = None

iterations = 40

print("Creating graph and compiling workflow...")
graph = create_graph(server=server, model=model, model_endpoint=model_endpoint)
workflow = compile_workflow(graph)
print("Graph and workflow created.")

def get_user_input():
    root = tk.Tk()
    root.withdraw()  # Hide the main window
    user_input = simpledialog.askstring("IELTS Writing Analyzer", "Enter your IELTS writing task:", parent=root)
    return user_input

def show_results(results):
    root = tk.Tk()
    root.withdraw()  # Hide the main window
    messagebox.showinfo("Analysis Results", results)

if __name__ == "__main__":
    verbose = False

    while True:
        user_input = get_user_input()
        if user_input is None or user_input.lower() == "exit":
            break

        dict_inputs = {
            "user_input": user_input
        }

        limit = {"recursion_limit": iterations}

        print("\nAnalyzing your writing...")
        final_event = None
        for event in workflow.stream(dict_inputs, limit):
            final_event = event
            if verbose:
                print(event)
            else:
                print(".", end="", flush=True)

        print("\nAnalysis complete.")

        should_continue = messagebox.askyesno("Continue?", "Would you like to analyze another piece of writing?")
        if not should_continue:
            break

print("Thank you for using the IELTS Writing Analyzer!")
analysis_node2_prompt = """
You are an expert IELTS examiner. Analyze the following text for task achievement and coherence. 
Consider the following:

1. Task Achievement:
   - Does the response fully address all parts of the task?
   - Is the position clear throughout the response?
   - Are the ideas well-developed with relevant examples?

2. Coherence and Cohesion:
   - Is the information logically organized?
   - Is there a clear progression of ideas?
   - Is there appropriate use of cohesive devices?

Use the relevant content in Knowledge Base during your analysis

Text to analyze:
{text}

Previous analysis results:
{analysis_results}

Knowledge Base:
{knowledge_base}

Provide a detailed analysis of task achievement and coherence, including specific examples from the text.
"""

analysis_node2_guided_json = {
    "type": "object",
    "properties": {
        "task_achievement": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "comments": {"type": "string"}
            },
            "required": ["score", "comments"]
        },
        "coherence": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "comments": {"type": "string"}
            },
            "required": ["score", "comments"]
        }
    },
    "required": ["task_achievement", "coherence"]
}

feedback_generation_prompt = """
As an IELTS writing expert, provide detailed feedback on the following text. 
Use the analysis results to guide your feedback. Focus on:

1. Grammar and vocabulary usage
2. Task achievement
3. Coherence and cohesion
4. Overall writing style

Use the relevant content in Knowledge Base for feedback

Text:
{text}

Analysis results:
{analysis_results}

Knowledge Base:
{knowledge_base}

Provide specific examples from the text and suggest improvements. 
Your feedback should be constructive and actionable.
"""

feedback_generation_guided_json = {
    "type": "object",
    "properties": {
        "grammar_vocabulary": {
            "type": "object",
            "properties": {
                "strengths": {"type": "array", "items": {"type": "string"}},
                "weaknesses": {"type": "array", "items": {"type": "string"}},
                "suggestions": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["strengths", "weaknesses", "suggestions"]
        },
        "task_achievement": {
            "type": "object",
            "properties": {
                "comments": {"type": "string"},
                "suggestions": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["comments", "suggestions"]
        },
        "coherence_cohesion": {
            "type": "object",
            "properties": {
                "comments": {"type": "string"},
                "suggestions": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["comments", "suggestions"]
        },
        "overall_feedback": {"type": "string"}
    },
    "required": ["grammar_vocabulary", "task_achievement", "coherence_cohesion", "overall_feedback"]
}

scoring_prompt = """
As an IELTS examiner, provide a detailed score breakdown for the writing sample based on the following criteria:

1. Task Achievement
2. Coherence and Cohesion
3. Lexical Resource
4. Grammatical Range and Accuracy

Use the provided analysis results to inform your scoring. For each criterion, provide a score out of 9 and a brief justification.
Use the relevant content in Knowledge Base while scoring

Analysis results:
{analysis_results}

Knowledge Base:
{knowledge_base}

Provide the overall band score as well as individual scores for each criterion.
"""

scoring_guided_json = {
    "type": "object",
    "properties": {
        "task_achievement": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "justification": {"type": "string"}
            },
            "required": ["score", "justification"]
        },
        "coherence_cohesion": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "justification": {"type": "string"}
            },
            "required": ["score", "justification"]
        },
        "lexical_resource": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "justification": {"type": "string"}
            },
            "required": ["score", "justification"]
        },
        "grammatical_range_accuracy": {
            "type": "object",
            "properties": {
                "score": {"type": "number", "minimum": 0, "maximum": 9},
                "justification": {"type": "string"}
            },
            "required": ["score", "justification"]
        },
        "overall_band_score": {"type": "number", "minimum": 0, "maximum": 9}
    },
    "required": ["task_achievement", "coherence_cohesion", "lexical_resource", "grammatical_range_accuracy", "overall_band_score"]
}

paraphrasing_prompt = """
As an expert IELTS writer, your task is to paraphrase and improve the given text to achieve an IELTS Band 8 standard. 
Focus on enhancing:

1. Task Achievement
2. Coherence and Cohesion
3. Lexical Resource
4. Grammatical Range and Accuracy

Use the relevant content in Knowledge Base while paraphrasing

Original text:
{text}

Current scores:
{scores}

Knowledge Base:
{knowledge_base}

Please provide:
1. A paraphrased version that addresses the weaknesses identified in the scoring, 
   while maintaining the original meaning and improving the overall quality to reach Band 8 standard.
2. A list of specific improvements made for each of the four focus areas.
3. Any overall comments on the improvements made.

Your response should be in JSON format as specified.
"""

paraphrasing_guided_json = {
    "type": "object",
    "properties": {
        "paraphrased_text": {"type": "string"},
        "improvements": {
            "type": "object",
            "properties": {
                "task_achievement": {"type": "array", "items": {"type": "string"}},
                "coherence_cohesion": {"type": "array", "items": {"type": "string"}},
                "lexical_resource": {"type": "array", "items": {"type": "string"}},
                "grammatical_range_accuracy": {"type": "array", "items": {"type": "string"}}
            },
            "required": ["task_achievement", "coherence_cohesion", "lexical_resource", "grammatical_range_accuracy"]
        },
        "overall_comments": {"type": "string"}
    },
    "required": ["paraphrased_text", "improvements", "overall_comments"]
}
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class AgentGraphState(TypedDict):
    user_input: str
    messages: Annotated[list, add_messages]

def get_agent_graph_state(state: AgentGraphState, state_key: str):
    if state_key == "user_input":
        return state["user_input"]

    elif state_key.endswith("_all"):
        agent_name = state_key[:-4]  # Remove '_all' from the end
        return [msg for msg in state["messages"] if msg.role == agent_name]

    elif state_key.endswith("_latest"):
        agent_name = state_key[:-7]  # Remove '_latest' from the end
        messages = [msg for msg in state["messages"] if msg.role == agent_name]
        return messages[-1] if messages else None

    else:
        return None

# Initialize the state
state = {
    "user_input": "",
    "messages": [],
}
from langchain_core.messages import HumanMessage
import json

def knowledge_base_loader(state):
    try:
        # Read the content of the file
        with open('D:/VentureInternship/AI Agent/ProjectK/knowledge_base.txt', 'r', encoding='utf-8') as file:
            knowledge_base_content = file.read()

        # Create a new knowledge base message
        knowledge_base_message = HumanMessage(
            role="knowledgeBase", 
            content=json.dumps({"knowledge_base": knowledge_base_content})
        )

        # Add the message to the state
        state["messages"].append(knowledge_base_message)

        # Log the action
        with open("D:/VentureInternship/AI Agent/ProjectK/response.txt", "w") as log_file:
            log_file.write(f"\nKnowledge Base Loader: Loaded knowledge base\n")

        return {"messages": state["messages"]}

    except Exception as e:
        error_message = f"Error loading knowledge base: {str(e)}"
        print(error_message)

        # # Log the error
        # with open("response.txt", "a") as log_file:
        #     log_file.write(f"\nKnowledge Base Loader Error: {error_message}\n")

        # Return an error state
        return {"error": error_message}
import spacy
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from langchain_core.messages import HumanMessage
import json

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

def preprocessing_tool(state):
    user_input = state["user_input"]

    # Tokenization
    words = word_tokenize(user_input)
    sentences = sent_tokenize(user_input)

    # SpaCy processing
    doc = nlp(user_input)

    # POS tagging
    pos_tags = [(token.text, token.pos_) for token in doc]

    # Named Entity Recognition
    named_entities = [(ent.text, ent.label_) for ent in doc.ents]

    preprocessed_data = {
        "text": user_input,
        "words": words,
        "sentences": sentences,
        "pos_tags": pos_tags,
        "named_entities": named_entities
    }

    # # Store preprocessed_data into a file (if needed)
    # with open("preprocessed_data.json", 'w') as file:
    #     json.dump(preprocessed_data, file, indent=4)

    # Update state with the correct message structure
    state["messages"].append(
        HumanMessage(role="preprocessing", content=json.dumps(preprocessed_data))
    )
        # Log the action
    with open("D:/VentureInternship/AI Agent/ProjectK/response.txt", "a") as log_file:
        log_file.write(f"\nPreprocessing Node{json.dumps(preprocessed_data)}\n")
    

    return {"messages": state["messages"]}
import textstat
from wordfreq import word_frequency
from difflib import SequenceMatcher
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
from langchain_core.messages import HumanMessage
import json
import spacy

# Load spaCy model (make sure it's loaded only once in your application)
nlp = spacy.load("en_core_web_sm")

def improved_grammar_check(text):
    errors = []
    doc = nlp(text)

    for sent in doc.sents:
        # Check for subject-verb agreement
        subject = None
        verb = None
        for token in sent:
            if token.dep_ == "nsubj":
                subject = token
            if token.pos_ == "VERB":
                verb = token
            if subject and verb:
                if subject.tag_ == "NNS" and verb.tag_ == "VBZ":
                    errors.append(f"Subject-verb disagreement: '{subject}' (plural) with '{verb}' (singular)")
                elif subject.tag_ == "NN" and verb.tag_ == "VBP":
                    errors.append(f"Subject-verb disagreement: '{subject}' (singular) with '{verb}' (plural)")
                break

        # Check for incorrect verb forms
        for token in sent:
            if token.text == "consist" and token.pos_ == "VERB":
                errors.append(f"Incorrect verb form: 'consist' should be 'consists'")
            if token.text == "have" and token.pos_ == "VERB" and token.head.pos_ != "VERB":
                errors.append(f"Incorrect verb form: 'have' should be 'has'")

        # Check for common mistakes
        text = sent.text.lower()
        if "there " in text and "shape" in text:
            errors.append("Incorrect use of 'there'. Did you mean 'their'?")
        if "then" in text and "than" not in text:
            errors.append("Possible confusion between 'then' and 'than'")
        if "it's" in text and "pointedness" in text:
            errors.append("Incorrect use of 'it's'. Did you mean 'its'?")

    return errors

def analysis_node1_tool(state):
    # Extract preprocessed data from the messages
    preprocessed_data_message = next((msg for msg in state["messages"] if msg.role == "preprocessing"), None)
    if not preprocessed_data_message:
        raise ValueError("Preprocessed data not found in state")

    preprocessed_data = json.loads(preprocessed_data_message.content)

    text = preprocessed_data["text"]
    words = preprocessed_data["words"]
    sentences = preprocessed_data["sentences"]

    # Improved grammar checking
    grammar_errors = improved_grammar_check(text)

    # Readability analysis
    readability_score = textstat.flesch_reading_ease(text)

    # Vocabulary assessment
    vocab_complexity = np.mean([word_frequency(word, 'en') for word in words])

    # Sentence similarity
    similarity_scores = []
    for i in range(len(sentences)):
        for j in range(i+1, len(sentences)):
            similarity = SequenceMatcher(None, sentences[i], sentences[j]).ratio()
            similarity_scores.append(similarity)

    # TF-IDF similarity
    tfidf_vectorizer = TfidfVectorizer()
    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)
    tfidf_similarity = np.mean(cosine_similarity(tfidf_matrix))

    analysis_results = {
        "grammar_errors": grammar_errors,
        "readability_score": readability_score,
        "vocab_complexity": vocab_complexity,
        "sentence_similarities": similarity_scores,
        "average_sentence_similarity": np.mean(similarity_scores),
        "tfidf_similarity": tfidf_similarity
    }

    # # Store analysis_results into a file (if needed)
    # with open("analysis_node1_results.json", 'w') as file:
    #     json.dump(analysis_results, file, indent=4)

    # Update state with the correct message structure
    state["messages"].append(
        HumanMessage(role="analysis_node1", content=json.dumps(analysis_results))
    )
            # Log the action
    with open("D:/VentureInternship/AI Agent/ProjectK/response.txt", "a") as log_file:
        log_file.write(f"\nAnalysis Node 1: {json.dumps(analysis_results)}\n")


    return {"messages": state["messages"]}
import json
import re
from datetime import datetime
from langchain_core.messages import HumanMessage

def format_report(state):
    try:
        # Extract all relevant messages from the state
        analysis_node1 = next((msg for msg in state["messages"] if msg.role == "analysis_node1"), None)
        analysis_node2 = next((msg for msg in state["messages"] if msg.role == "analysis_node2"), None)
        feedback = next((msg for msg in state["messages"] if msg.role == "feedback_generation"), None)
        scoring = next((msg for msg in state["messages"] if msg.role == "scoring"), None)
        paraphrasing = next((msg for msg in state["messages"] if msg.role == "paraphrasing"), None)

        # Initialize the formatted report
        formatted_report = "IELTS Writing Task Analysis Report\n"
        formatted_report += "=" * 40 + "\n"
        formatted_report += f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        # Add Analysis Results
        formatted_report += "Analysis Results:\n"
        formatted_report += "-" * 40 + "\n"
        if analysis_node1:
            formatted_report += f"Analysis Node 1:\n{json.dumps(json.loads(analysis_node1.content), indent=2)}\n\n"
        if analysis_node2:
            formatted_report += f"Analysis Node 2:\n{json.dumps(json.loads(analysis_node2.content), indent=2)}\n\n"

        # Add Feedback
        if feedback:
            formatted_report += "Feedback:\n"
            formatted_report += "-" * 40 + "\n"
            formatted_report += f"{json.dumps(json.loads(feedback.content), indent=2)}\n\n"

        # Add Scores
        if scoring:
            formatted_report += "Scores:\n"
            formatted_report += "-" * 40 + "\n"
            formatted_report += f"{json.dumps(json.loads(scoring.content), indent=2)}\n\n"

        # Add Paraphrased Content
        if paraphrasing:
            formatted_report += "Paraphrased Content:\n"
            formatted_report += "-" * 40 + "\n"
            paraphrased_content = json.loads(paraphrasing.content)
            if isinstance(paraphrased_content, dict) and "paraphrased_text" in paraphrased_content:
                formatted_report += f"{paraphrased_content['paraphrased_text']}\n\n"
            else:
                formatted_report += f"{json.dumps(paraphrased_content, indent=2)}\n\n"

        # Write the formatted report to report.txt
        with open('D:/VentureInternship/AI Agent/ProjectK/report.txt', 'w', encoding='utf-8') as file:
            file.write(formatted_report)

        print("Report generated successfully and saved to report.txt")

        # Add the formatted report to the state
        state["messages"].append(
            HumanMessage(role="formatted_report", content=formatted_report)
        )

        return {"messages": state["messages"]}

    except Exception as e:
        error_message = f"Error generating report: {str(e)}"
        print(error_message)
        return {"error": error_message}